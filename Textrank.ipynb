{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Textrank.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyP8j2wWNoXLg3MP8UqGM3Ty",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dr-song-summer-project/ChatBot_NLP/blob/main/Textrank.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QrVYf2cDcLYH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "049cbacd-bbd2-4962-f132-ae8da672ddda"
      },
      "source": [
        "!pip install konlpy"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting konlpy\n",
            "  Downloading konlpy-0.5.2-py2.py3-none-any.whl (19.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 19.4 MB 1.2 MB/s \n",
            "\u001b[?25hCollecting beautifulsoup4==4.6.0\n",
            "  Downloading beautifulsoup4-4.6.0-py3-none-any.whl (86 kB)\n",
            "\u001b[K     |████████████████████████████████| 86 kB 6.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: lxml>=4.1.0 in /usr/local/lib/python3.7/dist-packages (from konlpy) (4.2.6)\n",
            "Collecting JPype1>=0.7.0\n",
            "  Downloading JPype1-1.3.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.whl (448 kB)\n",
            "\u001b[K     |████████████████████████████████| 448 kB 40.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.6 in /usr/local/lib/python3.7/dist-packages (from konlpy) (1.19.5)\n",
            "Collecting colorama\n",
            "  Downloading colorama-0.4.4-py2.py3-none-any.whl (16 kB)\n",
            "Requirement already satisfied: tweepy>=3.7.0 in /usr/local/lib/python3.7/dist-packages (from konlpy) (3.10.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from JPype1>=0.7.0->konlpy) (3.7.4.3)\n",
            "Requirement already satisfied: requests[socks]>=2.11.1 in /usr/local/lib/python3.7/dist-packages (from tweepy>=3.7.0->konlpy) (2.23.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from tweepy>=3.7.0->konlpy) (1.15.0)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from tweepy>=3.7.0->konlpy) (1.3.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->tweepy>=3.7.0->konlpy) (3.1.1)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (2021.5.30)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (1.7.1)\n",
            "Installing collected packages: JPype1, colorama, beautifulsoup4, konlpy\n",
            "  Attempting uninstall: beautifulsoup4\n",
            "    Found existing installation: beautifulsoup4 4.6.3\n",
            "    Uninstalling beautifulsoup4-4.6.3:\n",
            "      Successfully uninstalled beautifulsoup4-4.6.3\n",
            "Successfully installed JPype1-1.3.0 beautifulsoup4-4.6.0 colorama-0.4.4 konlpy-0.5.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iJ2kIYpdcOXo"
      },
      "source": [
        "Rank"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lsEkG_pacPRl"
      },
      "source": [
        "import numpy as np\n",
        "from sklearn.preprocessing import normalize\n",
        "\n",
        "def pagerank(x, df=0.85, max_iter=30, bias=None):\n",
        "    \"\"\"\n",
        "    Arguments\n",
        "    ---------\n",
        "    x : scipy.sparse.csr_matrix\n",
        "        shape = (n vertex, n vertex)\n",
        "    df : float\n",
        "        Damping factor, 0 < df < 1\n",
        "    max_iter : int\n",
        "        Maximum number of iteration\n",
        "    bias : numpy.ndarray or None\n",
        "        If None, equal bias\n",
        "    Returns\n",
        "    -------\n",
        "    R : numpy.ndarray\n",
        "        PageRank vector. shape = (n vertex, 1)\n",
        "    \"\"\"\n",
        "\n",
        "    assert 0 < df < 1\n",
        "\n",
        "    # initialize\n",
        "    A = normalize(x, axis=0, norm='l1')\n",
        "    R = np.ones(A.shape[0]).reshape(-1,1)\n",
        "\n",
        "    # check bias\n",
        "    if bias is None:\n",
        "        bias = (1 - df) * np.ones(A.shape[0]).reshape(-1,1)\n",
        "    else:\n",
        "        bias = bias.reshape(-1,1)\n",
        "        bias = A.shape[0] * bias / bias.sum()\n",
        "        assert bias.shape[0] == A.shape[0]\n",
        "        bias = (1 - df) * bias\n",
        "\n",
        "    # iteration\n",
        "    for _ in range(max_iter):\n",
        "        R = df * (A * R) + bias\n",
        "\n",
        "    return R"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yDmCp-VacUT2"
      },
      "source": [
        "sentence\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pwCf_KzvcXGO"
      },
      "source": [
        "from collections import Counter\n",
        "import math\n",
        "import numpy as np\n",
        "import scipy as sp\n",
        "from scipy.sparse import csr_matrix\n",
        "from sklearn.metrics import pairwise_distances\n",
        "\n",
        "\n",
        "def sent_graph(sents, tokenize=None, min_count=2, min_sim=0.3,\n",
        "    similarity=None, vocab_to_idx=None, verbose=False):\n",
        "    \"\"\"\n",
        "    Arguments\n",
        "    ---------\n",
        "    sents : list of str\n",
        "        Sentence list\n",
        "    tokenize : callable\n",
        "        tokenize(sent) return list of str\n",
        "    min_count : int\n",
        "        Minimum term frequency\n",
        "    min_sim : float\n",
        "        Minimum similarity between sentences\n",
        "    similarity : callable or str\n",
        "        similarity(s1, s2) returns float\n",
        "        s1 and s2 are list of str.\n",
        "        available similarity = [callable, 'cosine', 'textrank']\n",
        "    vocab_to_idx : dict\n",
        "        Vocabulary to index mapper.\n",
        "        If None, this function scan vocabulary first.\n",
        "    verbose : Boolean\n",
        "        If True, verbose mode on\n",
        "    Returns\n",
        "    -------\n",
        "    sentence similarity graph : scipy.sparse.csr_matrix\n",
        "        shape = (n sents, n sents)\n",
        "    \"\"\"\n",
        "\n",
        "    if vocab_to_idx is None:\n",
        "        idx_to_vocab, vocab_to_idx = scan_vocabulary(sents, tokenize, min_count)\n",
        "    else:\n",
        "        idx_to_vocab = [vocab for vocab, _ in sorted(vocab_to_idx.items(), key=lambda x:x[1])]\n",
        "\n",
        "    x = vectorize_sents(sents, tokenize, vocab_to_idx)\n",
        "    if similarity == 'cosine':\n",
        "        x = numpy_cosine_similarity_matrix(x, min_sim, verbose, batch_size=1000)\n",
        "    else:\n",
        "        x = numpy_textrank_similarity_matrix(x, min_sim, verbose, batch_size=1000)\n",
        "    return x\n",
        "\n",
        "def vectorize_sents(sents, tokenize, vocab_to_idx):\n",
        "    rows, cols, data = [], [], []\n",
        "    for i, sent in enumerate(sents):\n",
        "        counter = Counter(tokenize(sent))\n",
        "        for token, count in counter.items():\n",
        "            j = vocab_to_idx.get(token, -1)\n",
        "            if j == -1:\n",
        "                continue\n",
        "            rows.append(i)\n",
        "            cols.append(j)\n",
        "            data.append(count)\n",
        "    n_rows = len(sents)\n",
        "    n_cols = len(vocab_to_idx)\n",
        "    return csr_matrix((data, (rows, cols)), shape=(n_rows, n_cols))\n",
        "\n",
        "def numpy_cosine_similarity_matrix(x, min_sim=0.3, verbose=True, batch_size=1000):\n",
        "    n_rows = x.shape[0]\n",
        "    mat = []\n",
        "    for bidx in range(math.ceil(n_rows / batch_size)):\n",
        "        b = int(bidx * batch_size)\n",
        "        e = min(n_rows, int((bidx+1) * batch_size))\n",
        "        psim = 1 - pairwise_distances(x[b:e], x, metric='cosine')\n",
        "        rows, cols = np.where(psim >= min_sim)\n",
        "        data = psim[rows, cols]\n",
        "        mat.append(csr_matrix((data, (rows, cols)), shape=(e-b, n_rows)))\n",
        "        if verbose:\n",
        "            print('\\rcalculating cosine sentence similarity {} / {}'.format(b, n_rows), end='')\n",
        "    mat = sp.sparse.vstack(mat)\n",
        "    if verbose:\n",
        "        print('\\rcalculating cosine sentence similarity was done with {} sents'.format(n_rows))\n",
        "    return mat\n",
        "\n",
        "def numpy_textrank_similarity_matrix(x, min_sim=0.3, verbose=True, min_length=1, batch_size=1000):\n",
        "    n_rows, n_cols = x.shape\n",
        "\n",
        "    # Boolean matrix\n",
        "    rows, cols = x.nonzero()\n",
        "    data = np.ones(rows.shape[0])\n",
        "    z = csr_matrix((data, (rows, cols)), shape=(n_rows, n_cols))\n",
        "\n",
        "    # Inverse sentence length\n",
        "    size = np.asarray(x.sum(axis=1)).reshape(-1)\n",
        "    size[np.where(size <= min_length)] = 10000\n",
        "    size = np.log(size)\n",
        "\n",
        "    mat = []\n",
        "    for bidx in range(math.ceil(n_rows / batch_size)):\n",
        "\n",
        "        # slicing\n",
        "        b = int(bidx * batch_size)\n",
        "        e = min(n_rows, int((bidx+1) * batch_size))\n",
        "\n",
        "        # dot product\n",
        "        inner = z[b:e,:] * z.transpose()\n",
        "\n",
        "        # sentence len[i,j] = size[i] + size[j]\n",
        "        norm = size[b:e].reshape(-1,1) + size.reshape(1,-1)\n",
        "        norm = norm ** (-1)\n",
        "        norm[np.where(norm == np.inf)] = 0\n",
        "\n",
        "        # normalize\n",
        "        sim = inner.multiply(norm).tocsr()\n",
        "        rows, cols = (sim >= min_sim).nonzero()\n",
        "        data = np.asarray(sim[rows, cols]).reshape(-1)\n",
        "\n",
        "        # append\n",
        "        mat.append(csr_matrix((data, (rows, cols)), shape=(e-b, n_rows)))\n",
        "\n",
        "        if verbose:\n",
        "            print('\\rcalculating textrank sentence similarity {} / {}'.format(b, n_rows), end='')\n",
        "\n",
        "    mat = sp.sparse.vstack(mat)\n",
        "    if verbose:\n",
        "        print('\\rcalculating textrank sentence similarity was done with {} sents'.format(n_rows))\n",
        "\n",
        "    return mat\n",
        "\n",
        "def graph_with_python_sim(tokens, verbose, similarity, min_sim):\n",
        "    if similarity == 'cosine':\n",
        "        similarity = cosine_sent_sim\n",
        "    elif callable(similarity):\n",
        "        similarity = similarity\n",
        "    else:\n",
        "        similarity = textrank_sent_sim\n",
        "\n",
        "    rows, cols, data = [], [], []\n",
        "    n_sents = len(tokens)\n",
        "    for i, tokens_i in enumerate(tokens):\n",
        "        if verbose and i % 1000 == 0:\n",
        "            print('\\rconstructing sentence graph {} / {} ...'.format(i, n_sents), end='')\n",
        "        for j, tokens_j in enumerate(tokens):\n",
        "            if i >= j:\n",
        "                continue\n",
        "            sim = similarity(tokens_i, tokens_j)\n",
        "            if sim < min_sim:\n",
        "                continue\n",
        "            rows.append(i)\n",
        "            cols.append(j)\n",
        "            data.append(sim)\n",
        "    if verbose:\n",
        "        print('\\rconstructing sentence graph was constructed from {} sents'.format(n_sents))\n",
        "    return csr_matrix((data, (rows, cols)), shape=(n_sents, n_sents))\n",
        "\n",
        "def textrank_sent_sim(s1, s2):\n",
        "    \"\"\"\n",
        "    Arguments\n",
        "    ---------\n",
        "    s1, s2 : list of str\n",
        "        Tokenized sentences\n",
        "    Returns\n",
        "    -------\n",
        "    Sentence similarity : float\n",
        "        Non-negative number\n",
        "    \"\"\"\n",
        "    n1 = len(s1)\n",
        "    n2 = len(s2)\n",
        "    if (n1 <= 1) or (n2 <= 1):\n",
        "        return 0\n",
        "    common = len(set(s1).intersection(set(s2)))\n",
        "    base = math.log(n1) + math.log(n2)\n",
        "    return common / base\n",
        "\n",
        "def cosine_sent_sim(s1, s2):\n",
        "    \"\"\"\n",
        "    Arguments\n",
        "    ---------\n",
        "    s1, s2 : list of str\n",
        "        Tokenized sentences\n",
        "    Returns\n",
        "    -------\n",
        "    Sentence similarity : float\n",
        "        Non-negative number\n",
        "    \"\"\"\n",
        "    if (not s1) or (not s2):\n",
        "        return 0\n",
        "\n",
        "    s1 = Counter(s1)\n",
        "    s2 = Counter(s2)\n",
        "    norm1 = math.sqrt(sum(v ** 2 for v in s1.values()))\n",
        "    norm2 = math.sqrt(sum(v ** 2 for v in s2.values()))\n",
        "    prod = 0\n",
        "    for k, v in s1.items():\n",
        "        prod += v * s2.get(k, 0)\n",
        "    return prod / (norm1 * norm2)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sD3kg53UcdCG"
      },
      "source": [
        "summarizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CbkRkLbtcfIB"
      },
      "source": [
        "\n",
        "class KeywordSummarizer:\n",
        "    \"\"\"\n",
        "    Arguments\n",
        "    ---------\n",
        "    sents : list of str\n",
        "        Sentence list\n",
        "    tokenize : callable\n",
        "        Tokenize function: tokenize(str) = list of str\n",
        "    min_count : int\n",
        "        Minumum frequency of words will be used to construct sentence graph\n",
        "    window : int\n",
        "        Word cooccurrence window size. Default is -1.\n",
        "        '-1' means there is cooccurrence between two words if the words occur in a sentence\n",
        "    min_cooccurrence : int\n",
        "        Minimum cooccurrence frequency of two words\n",
        "    vocab_to_idx : dict or None\n",
        "        Vocabulary to index mapper\n",
        "    df : float\n",
        "        PageRank damping factor\n",
        "    max_iter : int\n",
        "        Number of PageRank iterations\n",
        "    verbose : Boolean\n",
        "        If True, it shows training progress\n",
        "    \"\"\"\n",
        "    def __init__(self, sents=None, tokenize=None, min_count=2,\n",
        "        window=-1, min_cooccurrence=2, vocab_to_idx=None,\n",
        "        df=0.85, max_iter=30, verbose=False):\n",
        "\n",
        "        self.tokenize = tokenize\n",
        "        self.min_count = min_count\n",
        "        self.window = window\n",
        "        self.min_cooccurrence = min_cooccurrence\n",
        "        self.vocab_to_idx = vocab_to_idx\n",
        "        self.df = df\n",
        "        self.max_iter = max_iter\n",
        "        self.verbose = verbose\n",
        "\n",
        "        if sents is not None:\n",
        "            self.train_textrank(sents)\n",
        "\n",
        "    def train_textrank(self, sents, bias=None):\n",
        "        \"\"\"\n",
        "        Arguments\n",
        "        ---------\n",
        "        sents : list of str\n",
        "            Sentence list\n",
        "        bias : None or numpy.ndarray\n",
        "            PageRank bias term\n",
        "        Returns\n",
        "        -------\n",
        "        None\n",
        "        \"\"\"\n",
        "\n",
        "        g, self.idx_to_vocab = word_graph(sents,\n",
        "            self.tokenize, self.min_count,self.window,\n",
        "            self.min_cooccurrence, self.vocab_to_idx, self.verbose)\n",
        "        self.R = pagerank(g, self.df, self.max_iter, bias).reshape(-1)\n",
        "        if self.verbose:\n",
        "            print('trained TextRank. n words = {}'.format(self.R.shape[0]))\n",
        "\n",
        "    def keywords(self, topk=30):\n",
        "        \"\"\"\n",
        "        Arguments\n",
        "        ---------\n",
        "        topk : int\n",
        "            Number of keywords selected from TextRank\n",
        "        Returns\n",
        "        -------\n",
        "        keywords : list of tuple\n",
        "            Each tuple stands for (word, rank)\n",
        "        \"\"\"\n",
        "        if not hasattr(self, 'R'):\n",
        "            raise RuntimeError('Train textrank first or use summarize function')\n",
        "        idxs = self.R.argsort()[-topk:]\n",
        "        keywords = [(self.idx_to_vocab[idx], self.R[idx]) for idx in reversed(idxs)]\n",
        "        return keywords\n",
        "\n",
        "    def summarize(self, sents, topk=30):\n",
        "        \"\"\"\n",
        "        Arguments\n",
        "        ---------\n",
        "        sents : list of str\n",
        "            Sentence list\n",
        "        topk : int\n",
        "            Number of keywords selected from TextRank\n",
        "        Returns\n",
        "        -------\n",
        "        keywords : list of tuple\n",
        "            Each tuple stands for (word, rank)\n",
        "        \"\"\"\n",
        "        self.train_textrank(sents)\n",
        "        return self.keywords(topk)\n",
        "\n",
        "\n",
        "class KeysentenceSummarizer:\n",
        "    \"\"\"\n",
        "    Arguments\n",
        "    ---------\n",
        "    sents : list of str\n",
        "        Sentence list\n",
        "    tokenize : callable\n",
        "        Tokenize function: tokenize(str) = list of str\n",
        "    min_count : int\n",
        "        Minumum frequency of words will be used to construct sentence graph\n",
        "    min_sim : float\n",
        "        Minimum similarity between sentences in sentence graph\n",
        "    similarity : str\n",
        "        available similarity = ['cosine', 'textrank']\n",
        "    vocab_to_idx : dict or None\n",
        "        Vocabulary to index mapper\n",
        "    df : float\n",
        "        PageRank damping factor\n",
        "    max_iter : int\n",
        "        Number of PageRank iterations\n",
        "    verbose : Boolean\n",
        "        If True, it shows training progress\n",
        "    \"\"\"\n",
        "    def __init__(self, sents=None, tokenize=None, min_count=2,\n",
        "        min_sim=0.3, similarity=None, vocab_to_idx=None,\n",
        "        df=0.85, max_iter=30, verbose=False):\n",
        "\n",
        "        self.tokenize = tokenize\n",
        "        self.min_count = min_count\n",
        "        self.min_sim = min_sim\n",
        "        self.similarity = similarity\n",
        "        self.vocab_to_idx = vocab_to_idx\n",
        "        self.df = df\n",
        "        self.max_iter = max_iter\n",
        "        self.verbose = verbose\n",
        "\n",
        "        if sents is not None:\n",
        "            self.train_textrank(sents)\n",
        "\n",
        "    def train_textrank(self, sents, bias=None):\n",
        "        \"\"\"\n",
        "        Arguments\n",
        "        ---------\n",
        "        sents : list of str\n",
        "            Sentence list\n",
        "        bias : None or numpy.ndarray\n",
        "            PageRank bias term\n",
        "            Shape must be (n_sents,)\n",
        "        Returns\n",
        "        -------\n",
        "        None\n",
        "        \"\"\"\n",
        "        g = sent_graph(sents, self.tokenize, self.min_count,\n",
        "            self.min_sim, self.similarity, self.vocab_to_idx, self.verbose)\n",
        "        self.R = pagerank(g, self.df, self.max_iter, bias).reshape(-1)\n",
        "        if self.verbose:\n",
        "            print('trained TextRank. n sentences = {}'.format(self.R.shape[0]))\n",
        "\n",
        "    def summarize(self, sents, topk=30, bias=None):\n",
        "        \"\"\"\n",
        "        Arguments\n",
        "        ---------\n",
        "        sents : list of str\n",
        "            Sentence list\n",
        "        topk : int\n",
        "            Number of key-sentences to be selected.\n",
        "        bias : None or numpy.ndarray\n",
        "            PageRank bias term\n",
        "            Shape must be (n_sents,)\n",
        "        Returns\n",
        "        -------\n",
        "        keysents : list of tuple\n",
        "            Each tuple stands for (sentence index, rank, sentence)\n",
        "        Usage\n",
        "        -----\n",
        "            >>> from textrank import KeysentenceSummarizer\n",
        "            >>> summarizer = KeysentenceSummarizer(tokenize = tokenizer, min_sim = 0.5)\n",
        "            >>> keysents = summarizer.summarize(texts, topk=30)\n",
        "        \"\"\"\n",
        "        n_sents = len(sents)\n",
        "        if isinstance(bias, np.ndarray):\n",
        "            if bias.shape != (n_sents,):\n",
        "                raise ValueError('The shape of bias must be (n_sents,) but {}'.format(bias.shape))\n",
        "        elif bias is not None:\n",
        "            raise ValueError('The type of bias must be None or numpy.ndarray but the type is {}'.format(type(bias)))\n",
        "\n",
        "        self.train_textrank(sents, bias)\n",
        "        idxs = self.R.argsort()[-topk:]\n",
        "        keysents = [(idx, self.R[idx], sents[idx]) for idx in reversed(idxs)]\n",
        "        return keysents"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NEjLyODrckKs"
      },
      "source": [
        "utils"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A0bPELXUcl6y"
      },
      "source": [
        "from collections import Counter\n",
        "from scipy.sparse import csr_matrix\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "def scan_vocabulary(sents, tokenize=None, min_count=2):\n",
        "    \"\"\"\n",
        "    Arguments\n",
        "    ---------\n",
        "    sents : list of str\n",
        "        Sentence list\n",
        "    tokenize : callable\n",
        "        tokenize(str) returns list of str\n",
        "    min_count : int\n",
        "        Minumum term frequency\n",
        "    Returns\n",
        "    -------\n",
        "    idx_to_vocab : list of str\n",
        "        Vocabulary list\n",
        "    vocab_to_idx : dict\n",
        "        Vocabulary to index mapper.\n",
        "    \"\"\"\n",
        "    counter = Counter(w for sent in sents for w in tokenize(sent))\n",
        "    counter = {w:c for w,c in counter.items() if c >= min_count}\n",
        "    idx_to_vocab = [w for w, _ in sorted(counter.items(), key=lambda x:-x[1])]\n",
        "    vocab_to_idx = {vocab:idx for idx, vocab in enumerate(idx_to_vocab)}\n",
        "    return idx_to_vocab, vocab_to_idx\n",
        "\n",
        "def tokenize_sents(sents, tokenize):\n",
        "    \"\"\"\n",
        "    Arguments\n",
        "    ---------\n",
        "    sents : list of str\n",
        "        Sentence list\n",
        "    tokenize : callable\n",
        "        tokenize(sent) returns list of str (word sequence)\n",
        "    Returns피임\n",
        "    -------\n",
        "    tokenized sentence list : list of list of str\n",
        "    \"\"\"\n",
        "    return [tokenize(sent) for sent in sents]\n",
        "\n",
        "def vectorize(tokens, vocab_to_idx):\n",
        "    \"\"\"\n",
        "    Arguments\n",
        "    ---------\n",
        "    tokens : list of list of str\n",
        "        Tokenzed sentence list\n",
        "    vocab_to_idx : dict\n",
        "        Vocabulary to index mapper\n",
        "    Returns\n",
        "    -------\n",
        "    sentence bow : scipy.sparse.csr_matrix\n",
        "        shape = (n_sents, n_terms)\n",
        "    \"\"\"\n",
        "    rows, cols, data = [], [], []\n",
        "    for i, tokens_i in enumerate(tokens):\n",
        "        for t, c in Counter(tokens_i).items():\n",
        "            j = vocab_to_idx.get(t, -1)\n",
        "            if j == -1:\n",
        "                continue\n",
        "            rows.append(i)\n",
        "            cols.append(j)\n",
        "            data.append(c)\n",
        "    n_sents = len(tokens)\n",
        "    n_terms = len(vocab_to_idx)\n",
        "    x = csr_matrix((data, (rows, cols)), shape=(n_sents, n_terms))\n",
        "    return x\n"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JZa5Jqk-cqWh"
      },
      "source": [
        "word"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xeLtnfjLcsVv"
      },
      "source": [
        "from collections import defaultdict\n",
        "from scipy.sparse import csr_matrix\n",
        "\n",
        "\n",
        "def word_graph(sents, tokenize=None, min_count=2, window=2,\n",
        "    min_cooccurrence=2, vocab_to_idx=None, verbose=False):\n",
        "    \"\"\"\n",
        "    Arguments\n",
        "    ---------\n",
        "    sents : list of str\n",
        "        Sentence list\n",
        "    tokenize : callable\n",
        "        tokenize(str) returns list of str\n",
        "    min_count : int\n",
        "        Minumum term frequency\n",
        "    window : int\n",
        "        Co-occurrence window size\n",
        "    min_cooccurrence : int\n",
        "        Minimum cooccurrence frequency\n",
        "    vocab_to_idx : dict\n",
        "        Vocabulary to index mapper.\n",
        "        If None, this function scan vocabulary first.\n",
        "    verbose : Boolean\n",
        "        If True, verbose mode on\n",
        "    Returns\n",
        "    -------\n",
        "    co-occurrence word graph : scipy.sparse.csr_matrix\n",
        "    idx_to_vocab : list of str\n",
        "        Word list corresponding row and column\n",
        "    \"\"\"\n",
        "    if vocab_to_idx is None:\n",
        "        idx_to_vocab, vocab_to_idx = scan_vocabulary(sents, tokenize, min_count)\n",
        "    else:\n",
        "        idx_to_vocab = [vocab for vocab, _ in sorted(vocab_to_idx.items(), key=lambda x:x[1])]\n",
        "\n",
        "    tokens = tokenize_sents(sents, tokenize)\n",
        "    g = cooccurrence(tokens, vocab_to_idx, window, min_cooccurrence, verbose)\n",
        "    return g, idx_to_vocab\n",
        "\n",
        "def cooccurrence(tokens, vocab_to_idx, window=2, min_cooccurrence=2, verbose=False):\n",
        "    \"\"\"\n",
        "    Arguments\n",
        "    ---------\n",
        "    tokens : list of list of str\n",
        "        Tokenized sentence list\n",
        "    vocab_to_idx : dict\n",
        "        Vocabulary to index mapper\n",
        "    window : int\n",
        "        Co-occurrence window size\n",
        "    min_cooccurrence : int\n",
        "        Minimum cooccurrence frequency\n",
        "    verbose : Boolean\n",
        "        If True, verbose mode on\n",
        "    Returns\n",
        "    -------\n",
        "    co-occurrence matrix : scipy.sparse.csr_matrix\n",
        "        shape = (n_vocabs, n_vocabs)\n",
        "    \"\"\"\n",
        "    counter = defaultdict(int)\n",
        "    for s, tokens_i in enumerate(tokens):\n",
        "        if verbose and s % 1000 == 0:\n",
        "            print('\\rword cooccurrence counting {}'.format(s), end='')\n",
        "        vocabs = [vocab_to_idx[w] for w in tokens_i if w in vocab_to_idx]\n",
        "        n = len(vocabs)\n",
        "        for i, v in enumerate(vocabs):\n",
        "            if window <= 0:\n",
        "                b, e = 0, n\n",
        "            else:\n",
        "                b = max(0, i - window)\n",
        "                e = min(i + window, n)\n",
        "            for j in range(b, e):\n",
        "                if i == j:\n",
        "                    continue\n",
        "                counter[(v, vocabs[j])] += 1\n",
        "                counter[(vocabs[j], v)] += 1\n",
        "    counter = {k:v for k,v in counter.items() if v >= min_cooccurrence}\n",
        "    n_vocabs = len(vocab_to_idx)\n",
        "    if verbose:\n",
        "        print('\\rword cooccurrence counting from {} sents was done'.format(s+1))\n",
        "    return dict_to_mat(counter, n_vocabs, n_vocabs)\n",
        "\n",
        "def dict_to_mat(d, n_rows, n_cols):\n",
        "    \"\"\"\n",
        "    Arguments\n",
        "    ---------\n",
        "    d : dict\n",
        "        key : (i,j) tuple\n",
        "        value : float value\n",
        "    Returns\n",
        "    -------\n",
        "    scipy.sparse.csr_matrix\n",
        "    \"\"\"\n",
        "    rows, cols, data = [], [], []\n",
        "    for (i, j), v in d.items():\n",
        "        rows.append(i)\n",
        "        cols.append(j)\n",
        "        data.append(v)\n",
        "    return csr_matrix((data, (rows, cols)), shape=(n_rows, n_cols))"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dfw7NhtYc2OX"
      },
      "source": [
        "from konlpy.tag import Komoran\n",
        "\n",
        "komoran = Komoran()\n",
        "def komoran_tokenize(sent):\n",
        "    words = komoran.pos(sent, join=True)\n",
        "    words = [w for w in words if ('/NN' in w or '/XR' in w or '/VA' in w or '/VV' in w)]\n",
        "    return words"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PKm1DW74eLsF"
      },
      "source": [
        "text입력"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "6X879CnIeM7F",
        "outputId": "b9453f45-2713-4025-d11b-dd2aedc4dd22"
      },
      "source": [
        "from google.colab import files\n",
        "\n",
        "uploaded = files.upload()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-966d94f2-124d-4b6e-a7fe-6faf963297b4\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-966d94f2-124d-4b6e-a7fe-6faf963297b4\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving keyword.xlsx to keyword.xlsx\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0mOKpuXfeiT3"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "# path = '/content/newxlsx.xlsx'\n",
        "# df = pd.read_excel(path)\n",
        "# data = pd.DataFrame.to_numpy(df)\n",
        "\n",
        "# test = []\n",
        "# for x in data:\n",
        "#   test.append(x[0])\n",
        "\n",
        "\n",
        "# path = '/content/clustered_8.xlsx'  \n",
        "# df = pd.read_excel(path)\n",
        "# data = pd.DataFrame.to_numpy(df)\n",
        "\n",
        "\n",
        "# test = []\n",
        "# for x in data:\n",
        "#   if x[2] == 2:\n",
        "#     test.append(x[1])\n",
        "\n",
        "path = '/content/keyword.xlsx'\n",
        "df = pd.read_excel(path)\n",
        "data = pd.DataFrame.to_numpy(df)\n",
        "\n",
        "\n",
        "test = [[] for _ in range(19)]\n",
        "idx = 0\n",
        "for x in data:\n",
        "  # if x[2] == 1:\n",
        "  #   test[0].append(x[0])\n",
        "  if x[2] == 0:\n",
        "    continue\n",
        "  idx = x[2]\n",
        "  test[idx-1].append(x[0])"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DozUjBmmiUf4",
        "outputId": "fc7da688-4bab-41d3-9b20-5b161b753716"
      },
      "source": [
        "print(test[2])"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['\\xa01월 27일 생리 시작일이며 피임약 야즈를 도 중에 끊고 27일부터 다시 먹었습니다. 그런데 아직까지도 생리가 끝나지 않아서 질문 드려요. 약을 다시 끊어야 하나요? 예전에 먹을 때는 이런 적 없었습니다.', '\\xa02주 전에 생리 시작하면서 피임약 복용을 함께 시작했는데요, 지난주 토요일에 제가 다리를 다치면서 정신이 없어서인지 일, 월, 화 3일치 약 복용을 잊었습니다. 밤 10시경에 항상 먹었어서 일단 화요일 밤에 이틀치를 먹고 수요일 아침에 화요일 분을, 수요일 밤 10시부터 다시 원래대로 복용하고 있는데요. 약 복용을 잊고 있다가 생각나게 된 계기가 몸의 변화 때문입니다. 생리가 끝난 지 일주일밖에 안 됐는데 약을 안 먹는 며칠 동안 출혈이 조금씩 나 고 생리 시작할 때 만큼은 아니지만 배가 살살 아프더라구요. 다시 피임약 복용을 하고 있는데 출혈은 멈췄지만 가슴이 부 풀어 오르고 속이 메슥거리는 등 생리 전중 증상이 나타납니다. 계속 피임약을 복용해야 할까요? 왜 이러는지 걱정되네요.. br', '\\xa03일 후인 13일 날 피임약 복용이 끝나는 복용 3주차입니다 일주일 뒤 일정이 생겨서 생리를 미루고 싶은데 어떻게 해야 할까요? 도와 주세요 ㅜㅜ 20일까지 생리를 미루고 싶습니다! 1. 피임약을 추가 복용해서 미뤄야 하나요? 2. 피임약을 3일 기간 동안 끊고 지금 생리 후에 새로 복용하면 될까요? 언제 복용하면 될까요? br', '\\xa0뚱뚱하고 40대입니다. 생리를 3달 이상 안한 후 하기에 생리인 줄 알았으나 출혈이 멈추지 않아 피임약 복용하고 있읍니다. 피임약을 3주 먹고 1주 쉬라고 했으나 출혈양이 적어지기는 했으나 멈추지 않아 쉬지 않고 4주째 먹고 있읍니다. 피양이 다시 조금 증가 한 것 같은데 피임약을 쉬지 않고 먹으면 어떻게 되나요?', '\\xa0제가 4월부터 피임약을 복용하고 휴약기에 정상적으로 생리를 하고 5월에도 날짜를 맞춰서 복용을 했는데 몸이 아파서 1주일 정도 복용 후에 중단을 하고 지금까지 복용을 하지 않았습니다. 요번 6월부터 다시 복용을 시작하려고 하는데요 어플상 생리 예정일이 4째 주라고 되어 있는데요 원래 정상적으론 1째주에 하는 게 맞는데 복용을 중지하고 부정출혈이 생겨서 5월에 2번 생리를 했어요 이럴 경우에는 언제쯤 다시 복용을 해야지 효과를 볼 쑤 있을까요?', '\\xa0지금까지 생리를 하지 않아 이렇게 문의 드립니다제가 생리증후군이나 생리통이 있어 피임약을 복용 후 증상이 완화되긴 했는데 왜 생리를 하지 않는지요? 임신은 아닌데 말입니다.. 혹 내성이 생긴 건 아닌지 아님 다른 이유인지 해서 요 아직 폐경될 나이는 아닌 것 같은데... 제가 원래 생리가 좀 불 규칙한 편입니다,, 그래도 피임약 복용 전에는 한 달에 한 번은 했었읍니다. 그럼 부탁드립니다 br', '\\xa0대학교 실기시험 때문에 생리를 미뤄야 해서 경구피임약을 복용할려고 하는데 제가 생리를 시작하는 날이 실기날과 겹쳐 요 실기가 10월 8일 토요일이 그때 생리하는 날이라 시작하기 일주일 전에 약을 복용할려고 하는데 문제는 그날에만 실기가 있는 게 아니라 10월 15일 토요일 10월 22일 토요일도 실기가 있는 날이라 약을 멈추면 생리를 바로 시작한다고 하기에 10월\\xa0 23일까지 약을 복용할 생각입니다 그런데 약을 복용하는 내내 생리를 않하나요? 경구피임약을 계속 복용하여 10월 23일 날 약을 그만 먹고 1~3일 만에 생리를 한다는 데 그때 생리를 하고 나면 11월 첫 쨋주에 생리기간인데 시작한 지 일주일도 안 되서 또 생리를 하나요? 11월 15일에도 실기가 있습니다 그 전에 생리를 하면 안 되서 한다면 경구 피임약을 복용하면 효과가 있을까요?', '\\xa0피임약에 대해 궁금한 점이 있어서 문의 드립니다. 1.피임약을 복용하게 되면 자궁이 임신한 걸로 착각해서 생리를 안하게 되는데 그것 때문에 피임약을 복용하다 복용을 멈추면 임신성 탈모처럼 머리가 많이 빠진다고 하던데 맞나요? 2.피임약을 3달 정도 복용한 다치면 복용 기간 내에는 계속 생리를 안하는 건가요? 제가 어디서 듣기로는 피임약으로 생리주기를 맞추기도 한다는 데 그럼 3달 내내 생리를 안하다가 마지막 달에 생리를 하게 하는 건가요? 아니면 달달이 생리를 해가면서 맞추는 건가요? 3.만약 피임약을 복용하면서도 달달이 생리를 할 수 있게 된다면 그건 몸이 임신한 상태로 착각하지 않게 되는 건가요? 피임약을 한 몇 달 복용하려는데 복용하기에 앞서서 머리가 많이 빠지게 될까봐 걱정이 됩니다. br', '\\xa0경구피임약 야즈를 정해진 시간에 꾸준히 복용하는데요, 콘돔 없이 질 외 사정 관계를 가졌습니다. 5일 정도 후 휴약기에 생리를 했는데 이러면 임신 가능성은 전혀 없는 거죠?', '\\xa0제가 713에 생리 시작해서 (남은 피임약이 17개 남아서 17일간 저녁 11시에) 728까지 약 복용했는데요 728부터 부정출혈 있다가 81 오늘 생리 시작했는데 휴약기간 없이 다시 약 복용 해야 할까요? 오늘 약사분한테 물어봤는데 복용하라고 해서 일단 한 알 먹었어요 br', '\\xa0지금 경구피임약을 17일째 복용 중입니다 생리 예정일은 330일 이었는데 생리를 미루고자 생리 시작 7일 전 322일부터 복용 시작했어요 오늘 47일 질 내 사정을 했는데 사 후 피임약 먹어야 할까요? 생리 첫날 복용 한 경구피임약은 피임 효과가 없는 건가요? 답변 부탁드려요\\xa0 - br', '\\xa0대학교 실기시험 때문에 생리를 미뤄야 해서 경구피임약을 복용할려고 하는데 제가 생리를 시작하는 날이 실기날과 겹쳐 요 실기가 10월 8일 토요일이 그때 생리하는 날이라 시작하기 일주일 전에 약을 복용할려고 하는데 문제는 그날에만 실기가 있는 게 아니라 10월 15일 토요일 10월 22일 토요일도 실기가 있는 날이라 약을 멈추면 생리를 바로 시작한다고 하기에 10월\\xa0 23일까지 약을 복용할 생각입니다 그런데 약을 복용하는 내내 생리를 않하나요? 경구피임약을 계속 복용하여 10월 23일 날 약을 그만 먹고 1~3일 만에 생리를 한다는 데 그때 생리를 하고 나면 11월 첫 쨋주에 생리기간인데 시작한 지 일주일도 안 되서 또 생리를 하나요? 11월 15일에도 실기가 있습니다 그 전에 생리를 하면 안 되서 한다면 경구 피임약을 복용하면 효과가 있을까요?', '\\xa0제가 4월 24일에 생리하고 5월 6일 피임도구 활용해 관계했지만 첫 관계라 불안해 7일 날 사 후 피임약 복용 후 12일 날 생리 같은 출혈을 했습니다 산부인과가 서 초음파 검사했는데 5월 말일이나 6월 1일 날 생리를 할 것 같다는 데 저는 어제부터 피임약을 먹기 시작했어요 생리 첫날 부타 복용을 하는 게 맞다고 하는데 생리 끝나고 나부터 하면 약효 없나요??? 새 팩을 먹을 때 효과가 나타나려나요 이번 달은 안 나타나는 건지 좀 자세히 알려주세요... 멜리안 정 먹고 있습니다 멜리안 정도 피임 효과 있죠??? 순하다 해서 혹시나 효과 없을까 걱정되서요', '\\xa0경구피임약을 3팩을 복용하고 있었고 , 11월 30일을 마지막으로 4알을 남겨둔 채 피임약은 복용하지 않았습니다. (경구피임약은 클래라 정입니다. ) 그리고 12월 5일 6일 피임기구 없이 질 외 사정을 하였고, 12월 7일 생리통과 함께 생리인지 부정출혈인지는 모르겠습니다만, 4~6일 정도 했습니다. 만 약 12월 7일을 새로운 생리주기로 본다면 저번 주쯤에 생리를 해야 하는데 아직도 생리를 하지 않는 상태입니다. 그래서 혹시나 임신 가능성이 있을까 걱정이 되어서 질문드립니다. br', '\\xa0피임약 야즈 복용에 대해서 궁금한 게 있는데요. 3개월째 야즈 복용하고 있고 마지막 생리일이 11월 말부터 12월 초까지 했구요.. 제가 여행을 가면서 깜빡하고 피임약을 안 가져가서 12월 11일부터 현재까지 피임약 복용을 안하고 있는데 12월 14일부터 3일간 출혈이 있었는데 이걸 생리로 봐야 하나요 아님 단순 출혈인가요? 예정대로라면 지금쯤 생리가 있어야 하는데 하질 않아서요.. brtd trtbdy ta ble', '\\xa0이번 주에 수능을 보는 학생입니다. 수능 때 생리를 하는 것을 미루고자 11월 말에 예정이던 생리를 일주일 전부터 피임약을 복용하였습니다. 먹은 지 한 2주가 되어 가요. 그런데 한 1~2일 전부터 자궁 쪽에 통증이 있고 오늘은 더 아팠습니다. 허리도 아팠구요. 서 있거나 앉아 있으면 아파요. 어떻게 해야 할지 모르겠어요. 약을 먹는 것을 중단해야 할까요? 도와 주세요 ㅠㅠ 부탁드립니다.', '\\xa0피임약 첫 달 복용 휴약기 3일째에 생리를 했는데 양이 전보다 적고 기간이 평소보다 길었습니다 약 복용 중 2주 이후에 관계를 했는데 임신 가능성이 있는 건가요 br', '\\xa0생리 시작일 부터 피임약 복용 중, 12일째 되는 날 콘돔이 찢어져 질 내 사정을 하게 되었습니다. 피임약은 비슷한 시간대에 먹었고 잊어도 3시간 이내 복용 하였습니다. 그 후로도 똑같은 시간대에 피임약을 복용하였고 엊그제 휴약기를 시작했는데 생리를 하지 않습니다. 임신일까요? 그리고 비만일 경우 피임약의 효과가 줄어드나요? br', '\\xa0일정한 시기에 경구피임약을 복용했음에도 생리를 합니다.', '\\xa0사후 피임약 복용 된 지 정확히 한 달이 지났고 아직 생리를 시작 안 했는데 임신 확률이 있나요?..', '\\xa0제가 머시론을 생리 둘째 날부터 19일째 복용 중인데 21일째에 생리를 일주일 정도 더 미루고 싶어서 며칠 더 약을 먹고 휴약기를 가지려고 하는데 다른 약으로 이어서 먹어서 생리를 미룰 수 있나요? 그렇게 해도 될까요? 이어 먹으려는 약은 에이리스 인데 약국에 머시론이 다 떨어졌다고 해서 일단 사왔는데 에이리스로 이어서 일주일 정도 더 먹으면 그만큼 생리를 늦 출 수 있을까요?', '\\xa0여자친구 생리 주기가 매월 초인데 아마 2월 7일쯤에 사 전 피임약을 복용하고, 3월 3일까지 복용한 걸로 기억하고 있습니다. * 사전 피임약을 복용 후에도 생리를 멈추지 않고 계속해서 혈이 조금씩 나왔습니다. 3일 날 딱 피임약을 멈춘 상태에서 3~4일 정도 혈이 나오다가 지금은 멈춘 상태입니다. 피임약을 마지막으로 복용한 뒤 그날 관계를 가졌구, 질 내 사정을 했습니다. 아직 테스트기는 사용을 하지 않을 상태이구, 지금까지도 생리를 안한다고 하기에.. 물어볼 때 가 마땅히 없어서 지식이에 도움을 청해 봅니다.. 원래 사 전 피임약을 복용하면 7일 안에 생리를 한다고 하는데..ㅠㅠ 임신 가능 여부와 진단을 받고 싶습니다.', '\\xa0몇 달간 꾸준히 21일 복용 + 7일 휴약을 해왔습니다. 11월에 마지막으로 21정을 복용 후 휴약기에 생리를 하는 중에 질내 사정을 하였고, 이후 휴약기가 끝난 후 12월부터는 피임약 복용을 중단했습니다. 그리고 현재 12월 생리 예정일이 이틀 정도 지났는데 아직 생리를 안하네요.. 이 경우 임신 가능성이 있나요? +추가로 질문 좀 드립니다 ㅠㅠ 12월에도 관계는 하였으나 콘돔은 착용 한 상태로 했습니다. 이 경우에는 임신 가능성이 있나요? 그리고 생리가 늦어지는 다른 원인이 있는지 궁금합니다..', '\\xa02월 22일 피임 없이 관계를 가지고 바로 다음 아침 날 응급피임약을 복용한 후 3월 5일 날 피검사로 임신 가능성 수치 0, 7일 아침 임테기 해보려는데 생리를 했습니다. 그리고 원래 같으면 4월 9일에 생리를 시작했어야 했는데 오늘까지 하고 있지 않습니다. 응급피임약의 부작용이라고 여겨도 되는 걸까요? 괜히 불안해집니다...', '\\xa0경구피임약으로 생리유도를 할 수 있을까요? 생리 첫날부터 해라고 하는데 생리를 안하는데.... 어떻게 하나요', '\\xa0생리 과 다로 경구 피임약 복용을 했는데 요 10일간 멜리안 복용을 했고 부작용이 심해 바로 야즈를 복용 했어요 야즈를 딱 14 알 먹고 4일 휴약기를 가지려고 했는데 시험 날짜에 생리를 할까봐 18 알을 먹고 (피임약을 총 28알 복용했습니다.) 지금 휴약기 3일 찬데요 어제부터 갈색 냉만 나오고 생리를 안 해요... 이럴 수도 있나요 내일 휴약기가 끝나는데 생리가 안 나와도 다시 약 복용 시작해도 되나요?', '\\xa0- 혈압\\xa0 - 키체중\\xa0 cm\\xa0 kg - 가족력(가족, 친척의 건강, 질환 등)\\xa0 - 과거 병력\\xa0 varian cyst - 상담 내용\\xa0 저는 1년 전에 난 소난종이 생겨서 수술 이후 호르몬 조절이 필요하다고 하여 피임약을 먹기 시작했는데. 홀몬주사를 처음에 의사 선생님이 권유 하셨지만 홀몬주사가 부작용이 많이 나타난다고 하여 피임약을 복용하고 있었습니다. 그런데 그동안에 피임약 복용 중 마지막 주에 항상 생리가 있었는데 4개월 전부터 피임약 복용 후 4일 휴약하는 기간에 생리를 안하고 있습니다. 참고로 제가 먹고 있는 피임약은 24일 먹고 휴약하는 기간은 4일입니다.', '\\xa0제가 5월 22일 금요일 부터 생리를 시작해 5월 24일 일요일 생리 3일째에 접어듭니다. 저는 생리를 하면 4일~5일 정도 하는데요 5월 24일 24시에 첫 경구 피임약을 복용하고 5월 24일 22시 30분에 두번째 경구 피임약을 복용하였습니다 그런데 5월 24일 22시에 남자친구와 관계를 가지고 질 내 사정을 해버렸는데요.. 지금 생리 기간이기도 하고 경구피임약도 두알째 먹는 중인데 혹시 임신 가능성이 있을까요..?', '\\xa07~8개월 전에 생리를 3주 동안 한 적이 있어 산부인과 찾아갔는데.. 호르몬 임발란스라고 해서 출혈이 고여 있다고 하더라고요. 그래서 호르몬 약을 먹고 좋아지고 피임약을 주셔서 일단 단분간은 피임약을 먹자고 하셔서 옅에 먹었습니다. 문제는 요~ 2~3달 전부터 피임약을 먹는데도 생리를 해야 하는 시기 일주일 정도 전부터 출혈이 나네요.... 이상이 있는 거 맞죠? 일단 오늘 큰 병원 찾아가 봤는데 호르몬 수치라도 검사하면 좋지만 피임약을 먹고 있는 상태라서 불편하더라도 3개월 끊고 그때 다시 검사를 해보자고 하네요. 6개월 전에 자궁암 검사도 다 해봤는데 다 깨끗하게 나왓어요. 갑작스러운 체지방 감량 때문에도 이런 변화가 가능한가요? 제가 몸무개로 따지면 하나도 안 빠졋는데 운동으로 인해 근력양을 많이 올리고 체지방량을 한.. 8~10 프로를 쭐 엿어요. 갱년기가 빨리 올 수 있다는 미국에서 하는 말도 있던데.. 그럴 수도 있나요? 살을 찌워야 할까요? ㅠㅠ 걱정스럽네요....', '\\xa024살 여자인데요 생리 시작 후 첫째날부터 계속 피임약을 먹었는데 지금 생리 6일차 인데 끝나야 하는데 끝나지 않고 소량이 긴 한데 계속 생리를 해요...', '\\xa0생리예정일인데 생리를 안합니다. 3월 5일(화)에 생리 전날처럼 갈색 냉과 소량이 출혈이 있어서 경구 피임약 복용을 시작했습니다. 그런데 4일간 계속 갈색 냉과 소량의 출혈만 지속되다가 3월 9일(토)에 본격적인 생리를 시작했습니다. 경구피임약은 3월 5일(화) 21일 정 정확하게 복용해서 3월 25일(월)에 복용 완료했습니다. 3월 9일, 16일, 23일, 30일, 31일에 질내 사정으로 관계 가졌구요. 휴약기 4일차 정도인 3월 29일(금)에 생리 전과 비슷한 갈 생냉이 있었으나 2일 나오다 말았습니다. 4월 4일 아침에 테스트 기 해봤을 때 비 임신 나왔구요. 직전 생리 시작을 3월 9일(토)라고 가 정하면 오늘이 생리 예정일이 긴 하나 3월 5일(화)에 소량 출혈이 있었건 것과 그날부터 피임약을 복용한 것이 신경 쓰여서 질문 올립니다. 위와 같은 방식으로 복용하였고 성관계를 가졌는데 정상적인 피임 효과를 기대할 수 있나요? 확실한 비 임신을 확인하고 싶다면 최종적으로 언제 테스트기를 해보는 것이 좋을까요?', '\\xa0여자친구가 9월 17일에 생리를 시작해서 22일에 끝났는데요. 그 이후 생리를 안하다가 오늘 했거든요. 40일 좀 넘은 거죠...? 10월 12일 그리고 10월 22일에 관계를 가졌는데 모두 피임을 했구요. 22일은 불안하다고 해서 사 후 피임약을 복용했어요. 그런데 오늘 생리 했는데... 생리 같다고는 하는데 갈색 피가 묻어 있었다고 하네요. 갈색 피는 착상 혈이라고 많이 그러시던데 피임을 잘해서 착상 혈 일리는 없을 거 같은데... 혹시 저번 주에 사 후 피임약을 복용해서 그런 건 아닌가 궁금해서요. 오늘로부터 6일 전에 복용한 거네요. 착상혈이 아닐 경우엔 호르몬 이상으로 무배란 출혈이라는 갈색 피가 나올 수도 있다던데, 그러면 사 후 피임약 때문에 그런 건가요?? 아니면 설마 임신인 가요...? 피임은 제대로 했구요... 이틀 전에 임신테스트기도 했는데 음성 나왔구요... 생리가 원래 34~40일로 불규칙적이긴 한데 그냥 단순히 사 후 피임약이나 피로나 스트레스 때문에 갈색 피가 나올 수도 있는 건가요?? 정상적인 생리인데도 갈색이 나오나요?? 상담 내용을 요약해보면... 저번 달 생리 시작일로부터 41일 만에 갈색 피가 나온 거구요. 6일 전인 10월 22일엔 사 후 피임약을 복용했고 10월 12일, 22일 관계 시 피임은 다했습니다. 오늘 나온 갈색 피는 정상적인 생리인가요. 아니면 무배란 출혈인가요...? 아니면...임신인가요...? 답변 부탁드려요...', '\\xa0- 상담 내용\\xa0 제가 자궁 내막증 때문에 피임약으로 3개월 동안 쉬지 않고 먹었거든요.. 그런데 마지막 약을 다 먹었을 때 병원에 가지 못했어요 1월 초쯤에야 가게 될 거 같은데요.. 약을 12월 초? 11월 말 그때쯤에 다 먹었거든요 다 먹고 난 후 3, 4일 정도는 아주 조금 피가 나오긴 했거든요.. 그뿐이지 생리는 아직 안 나오고 있어요 약을 다 먹은 후부터 지금까지 3~4번 남자친구와 성관계를 가지긴 했는데.. 콘돔은 끼지 않고 했어요 언제 했는지는 잘 기억은 안나 구요.. 임신은 아닐 거 같은데 그래도 혹시 모르니까 적었구요.. 임신 증상 같은 것도 없구요 원래 한 달은 건너뛰고 생리를 하는 건가요 ? 병원 가기 전까지 불안하고 스트레스 받아서 힘드네요 ㅠㅠ 힘드시겠지만 그래도 친절한 답변 부탁드릴게요.', '\\xa0생리가 끝난 후 1일?2일? 뒤에 질내 사정을 했는데 임신 가능성이 있을까요..? 임신하고 싶지 않은데 사 후 피임약을 복용해야 할까요? 질 내 사정을 한 날은 16일인데 시간이 쫌 지나긴 했어요..', '\\xa0피임약 한 팩 다 먹고 두팩 2주 정도째 복용 중인데 생리 기간에 질 내 사정을 하면 임신 확률이 낮겠죠? 피임약 시간은 잘 지켰고 5번 정도 오차가 있었는데 항상 먹는 시간 30분 안팎의 오차였어요', '\\xa0- 성별\\xa0 여 - 혈압\\xa0 정상 - 키체중\\xa0 168 cm\\xa0 50 kg - 가족력(가족, 친척의 건강, 질환 등)\\xa0 - 과거 병력\\xa0 - 상담 내용\\xa0 피임약을 복용합니다 . 1월 11일~16일까지 생리기간이었구요 계속 피임약 복용 중에 25일 출혈이 있어서 ...26일부터 약을 안 먹었는데 27일부터 출혈 양이 조금 더 많아졌어요 심하게 많은 것은 아니지만 생리하는 정도... 이것도 생리인지 다른 이상 출혈인지.. 약 복용은 어찌해야 하는지. 궁금합니다', '\\xa0제가 지금고 1학년인데 제가 7월 20일 날쯤 일본 해외여행을 가서 딱 그 시기에 생리를 해가 지구 ㅜㅜ 처음으로 피임?약을 먹어보려 하는데 이 피임약이 아예 그 달은 생리를 다음달로 미뤄서 그달은 안 하는 건가요?? 그리고 대충 먹을려면 2주 전에 먹는 걸로 알고 잇는데 그땐 또 학교 시험이 잇어서.. 부작용이 나타나면 또 어쩔까 해서.. 답변 부탁드립니다', '\\xa0피임도 하고 생리도 미루고 싶어요 지금 피임약 두 달째 먹고 있는데 이번 달에 2주를 미루고 싶어요 그리고 끊고 생리를 하고 7일 휴약기를 가지고 피임약 세 번째 달을 시작할 거에 요 그렇다면 7일 휴약기 가지고 다음 피임약을 먹을 때 (세 번째 달)도 똑같이 피임 효과가 있는 거 맞나요?', '\\xa0생리 시작 일부터 7일 이내에 사 전 피임약을 먹고 일주일 동안 약을 먹고 관계를 했는데 콘돔 없이 질 외 사정을 했는데 그리고 관계 후 약을 중단했는데 일주일째인데 생리를 안해서 그러는데 아무 문제 없겠죠? 저번에는 항상 5일 안으로 다시 했는데 불안해서 그래요 ㅠㅠ 제발 알려주세요', '\\xa09월 15일에 경구피임약을 처음 복용했습니다. 10월 5일에 마지막 21일치 피임약을 먹고 10월 8일부터 일주일간 생리를 했습니다. 3일째 10월 10일부터 생리 양이 줄어들어 성관계를 했구요 콘돔 없이 질 외 사정했습니다. 경구피임약은 그 이후로 복용하지 않았구요 그런데 10월 14일부터 지금까지 생리를 하지 않습니다. 임신일 가능성이 있을까요?', '\\xa0의견을 여쭙고 싶어서 질문드려요. 최근 3개월 제 생리주기는 4월 12~16일 5월 13~17일 6월 10~14일 이었는데 요 7월에 13일~17일 동안 해외여행 예정이라 생리를 미루려고 했는데 생리하기 전에 잘 붓고 몸이 많이 피로해서 미리 하고 싶어요 ㅜㅜ 그래서 약국에서 피임약인 멜리안을 사와 서 오늘(6월 16일)부터 7월 2일까지 17일 동안 복용하고 중단하면 7월 4~6일쯤에 생리를 시작해서 원래주 기인 10일~12일 정도 보다 미리 할 수 있을까요? 약국 두 곳에 여쭤봤더니 한 분은 가능하다시고 한 분은 그렇게 하면 피임약 중단 후에 소퇴성출혈로 생리를 하고 원래 주기일 때 생리를 또 할 수도 있다고 해서 요ㅜㅜ 의 사 선생님의 의견을 듣고 싶어요! 도와 주세요! **참고로 피임약 복용은 이번이 처음입니다', '\\xa0- 상담 내용\\xa0 정확한 생리 주기는 없습니다. 2010년 11월 7일, 12월 16일, 이런 식으로 했구요,, 1월 1일에 성관계를 맺고 불안해서 1월 3일에 사 후 피임약을 복용한 후 9일에 생리를 했습니다 그다음에 며칠 전인 23일에 성관계를 맺었는데 완전 질 내 사정은 아니 구 반질 내 사정?....말이 이상한가요 ㅠㅠ 확실한 질 외 사정은 안했습니다...... 배란기에 대해 아예 신경을 안 쓰고 있다가 오늘에서야 보고 배란 기랑 겹치는 것 같더라구요... (계산 해주는 사이트에 봐도 생리 주기별로 계산해보니 싹다 23일 이 있더라구요..ㅠㅠ) 사후 피임약을 복용하기엔 이 미 늦었더라구요....;;;;;; 인터넷에 검색해 보니까 사 후 피임약 복용 후에 배란기가 늦어질 수도 있다고 하더라구 요 그리고 배란기라는 것이 생리가 규칙적인 사람한테 딱 적용된다고도 하더라구 요 일말의 희망과 함께 상담을 요청합니다', '\\xa012월 초에 중요한 일이 있어서 그때까지 생리를 미루려고 하는데요, 제가 알기로 생리주기 변경과 피임 효과를 보려고 복용하는 경구피임약은 복용법이 다르다고 알고 있어서요. 오늘 생리 1일째이고, 피임 효과와 생리도 12월까지 안하도록 미루고 싶은데 언제 어떻게 복용해야 하나요?', '\\xa0파일 첨부한 사진 답변에 대한 질문드립니다. 생리 둘 중 하나 시작하는 첫째 날에 피임약 21일간 복용 7일 휴식을 하라고 권하시는 게 맞나요? (피임약 복용이 피임 목적이 아닌 다낭성난소증후군으로 인한 불규칙적인 생리주기를 교정하기 위함입니다.)', '\\xa0제가 한 달 반동안 피임약을 꾸준히 복용하고 있었는데 중간에 휴약기가 아닐 때에 임의로 약을 중단했습니다 약을 안 먹기 시작한 지 2.3일 뒤에 바로 생리를 했고 그 다음달에 원래 휴약기 이었던 주에 생리를 했습니다 그리고 이번 달에 생리가 아직 없는데 피임 약 먹기 전 관계를 한 번 했는데요 약을 끊고 이렇게 두 번이나 생리를 했으면 임신 가능성은 아예 없는 거죠? 그리고 지금 성형외과 약을 3주간 복용하다가 끊었습니다 그것 때문에 생리를 안하고 있는 건지 궁금합니다']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NEou5krLdsXD",
        "outputId": "9ad09ecc-c0ba-45da-c283-7dc70252a555"
      },
      "source": [
        "# summarizer = KeysentenceSummarizer(\n",
        "#     tokenize = komoran_tokenize,\n",
        "#     min_sim = 0.5,\n",
        "#     verbose = False\n",
        "# )\n",
        "\n",
        "# keysents = summarizer.summarize(test, topk=5)\n",
        "# # print(keysents)\n",
        "# for x in keysents:\n",
        "#   print(x)\n",
        "\n",
        "summarizer = KeysentenceSummarizer(\n",
        "    tokenize = komoran_tokenize,\n",
        "    min_sim = 0.5,\n",
        "    verbose = True\n",
        ")\n",
        "\n",
        "keysents = summarizer.summarize(test[6], topk=5)\n",
        "for sent_idx, rank, sent in keysents:  \n",
        "  print(f'{sent_idx} : {rank} :: {sent}')"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\rcalculating textrank sentence similarity 0 / 35\rcalculating textrank sentence similarity was done with 35 sents\n",
            "trained TextRank. n sentences = 35\n",
            "16 : 1.3416150679141858 ::  strng 질문1.strng 피임약 질문하기 전에요 3달 전부터 생리가 3일 정도만 하고 끗 나는데 왜 그런 거죠 ㅠ원래 5~7일 정도였는데 ㅠㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡstrng 질문2.strng 피임약 이번에 처음 복용했어요 생리 시작하는 날 바로 먹고 처음 2주 정도는 피임 잘 안 된다 해서 관계 안 하고 2주 뒤에 했구요 제 때 제때 시간 맞춰서 잘 먹었는데 7일 휴약기간 동안 생리가 나와야 하는데 안 나오네요 ㅠ 혹시 피임잘 안되서 그런 건가 하고 임신테스트 기사서 검사해봤는데 임신 아니더라구요 근데 제가 생리주기가 불순하기도 하고 쫌길 기도한 데 34일~40일 정도 해여 6월-22일 생리 7월-25일 생리 이렇거든요ㅜ 오늘이 17일 이니까 기간상 으로 봤을 때는 생리 시작할라면 약 10일 정도 지나야 되요제가 질문하고 싶은 거는 요ㅠ 1. 피임약 봉용 후 7일 휴약기간 동안 생리를 안해도 8일째 되는 날 약을 다시 복용해도 되나요? 2. 아니면 생리나올 때까지 기다렸다가 복용해야 되나요? 3. 만 약 8일째 되는 날 복용한다면 이번 달 생리는 언제나오는 거죠 ㅠㅠ 4. 그냥 8일째 되는 날 피임약 안 먹고 남자친구 보고 콘돔 사용하라고 할까요?.. 1년 반 정도 만나면서 관계를 가졌는데 계속 콘돔을 사용하다가 좀 불편하고 혹시 몰라서 피임약 한번 복용해본 거거든요 br\n",
            "11 : 1.2693250300861916 ::  피임약을 2월 8일 서부터 먹고 있습니다. 생리주기는 불규칙합니다. (피임약 규칙적으로 먹었을 땐 30일이었는데 저번 달은 40일이 더군요.)만 약 피임약을 하루 정도 빼고 약 복용하면 피임은 되지 않고 생리만 안 하게 되잖아요? 그럼 배란 일은 대략 언 제쯤 되나요? 제가 알기론 보통 피임약 복용 중단 후 생리 끝나고 나서 배란기가 시작된다고 하던데 , 만약 하루 정도 약을 건너 뛰어서 피임 효과를 없애고 생리만 하지 않게 하면, 원래 배란 예정일에 배란을 하게 되는 건가요, 제 핸드폰 앱에 있는 배란 예정일은 26~3.3 일 이 네 여.또, 산부인과 가면 정확한 배란 일을 알 수 있는지 궁금합니다. 어떤 검사가 시행되고, 비용은 어느 정도 인지 알려주세요 br\n",
            "3 : 1.2578473870491864 ::  생리가 끝난 당일 부터 피임약 복용을 시작하면 원래 다음달 예정일이 16일부터인데 1주일이 늘어나게 되는 건가요? 근데 오늘부터 먹으면 21일 후에 시작하는 거면 16일에 생리를 시작하는 게 맞는 것 같은데.. 만약에 오늘부터 21정을 먹고 휴약기 기간에 생리 시작 후 끝나는 날부터 또 다시 복용하면 그 다음날부터 바로 질 내 사정을 해도 되나요?\n",
            "23 : 1.2239937934469234 ::  제가 대충 3개월 정도 경구피임약을 먹었습니다 그런데 콘돔 피임을 해볼까 하고 12월 3일까지 약을 먹고 그다음부터는 안 먹었습니다 근데 남자친구와 저 둘 다 콘돔피임에 별로 만족감을 못 느껴서 저는 생리 시작할 때 먹어야 된단걸 까먹고 12월 28일에 경구피임약을 복용하였습니다 그리고 1월 1일에 관계해서 질 내 사정했습니다 피임이 됐을까요?ㅠ 생리는 29일마다 한번합니다ㅠ 정리하자면 1 생리 11월 10일에 시작 그리고 12월 8일에 시작(즉 생리주기 29일) 2 12월 3일까지 약 먹고 12월 28일에 약 복용(생리시작하고 먹은 게 아님) 3 1월 1일 관계 질내 사정 사후피임약 먹어야 되나요 ㅠ 저는 경구피임약 먹기 전에 사 후 피임약을 두 번 정도 먹어서 별로 먹고 싶지 않은데요 ㅠㅠ 임신 가능성이 있는지 요ㅜ\n",
            "6 : 1.2181729230267058 ::  제가 생리 시작한 지 1~2일째에 머시론을 복용하기 시작했고, 오늘 10알째 먹었는데 콘돔이 터져서 질 내 사정이 됐어요 ㅠ 약 설명서에는 7일째부터 피임 효과가 나타난다고 하는데, 사 후 피임약 처방 받아야 되나요? 임신 확률이 높은가요? 피임약은 오 분 정도? 차이나게 먹은 적은 있지만 꾸준히 같은 시간에 복용했어요 br\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0A0Sox9Mfki0"
      },
      "source": [
        "docs = ['list of str form', 'sentence list']\n",
        "\n",
        "keyword_extractor = KeywordSummarizer(\n",
        "    tokenize = komoran_tokenize,      # YOUR TOKENIZER\n",
        "    window = -1,\n",
        "    verbose = False\n",
        ")\n",
        "\n",
        "keywords = keyword_extractor.summarize(test, topk=30)\n",
        "for word, rank in keywords:\n",
        "    print(word, rank)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PjYZyRQW-LJV",
        "outputId": "e2a1e99a-8b31-4c10-d28c-3e0d6db8fb9c"
      },
      "source": [
        "for i in range(19):\n",
        "  print(f'=================={i+1}번째====================')\n",
        "  keywords = keyword_extractor.summarize(test[i], topk=10)\n",
        "  for word, rank in keywords:\n",
        "      print(word, rank)"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "==================1번째====================\n",
            "먹/VV 2.874699472361487\n",
            "되/VV 1.896231742437004\n",
            "피임약/NNP 1.877587457187372\n",
            "비타민/NNP 1.387363707888139\n",
            "정/NNP 1.3052228591371025\n",
            "있/VV 1.1926259825938477\n",
            "경구/NNG 1.1470127162051185\n",
            "피임/NNP 1.1130538799875076\n",
            "하/VV 1.0632976487754808\n",
            "말/NNG 0.8962953109808395\n",
            "==================2번째====================\n",
            "하/VV 16.707718849379663\n",
            "일/NNB 13.64215235877169\n",
            "생리/NNG 12.889681041760678\n",
            "피임약/NNP 10.877405467525534\n",
            "먹/VV 9.378196340773256\n",
            "복용/NNG 9.349282790816225\n",
            "후/NNG 7.700320598492748\n",
            "관계/NNG 7.386592316703711\n",
            "임신/NNP 7.268656747552454\n",
            "있/VV 6.794992799841826\n",
            "==================3번째====================\n",
            "생리/NNG 15.360384761252103\n",
            "하/VV 14.8422122075201\n",
            "복용/NNG 10.850170764676163\n",
            "피임약/NNP 9.618958225308003\n",
            "일/NNB 8.14524089085127\n",
            "있/VV 4.769472615091315\n",
            "먹/VV 4.734686651836285\n",
            "약/NNG 4.413240739760327\n",
            "시작/NNG 3.8623017890965694\n",
            "후/NNG 3.3724686834541964\n",
            "==================4번째====================\n",
            "먹/VV 13.304344562533124\n",
            "복용/NNG 10.72449752207666\n",
            "일/NNB 9.017863894554894\n",
            "생리/NNG 8.969702498538274\n",
            "피임약/NNP 8.907499610494378\n",
            "효과/NNG 6.791446339090178\n",
            "하/VV 6.498418652904736\n",
            "피임/NNP 6.147591072067598\n",
            "있/VV 5.587366511485572\n",
            "시/NNB 5.495993515227879\n",
            "==================5번째====================\n",
            "하/VV 20.8024088818349\n",
            "먹/VV 15.994628574927393\n",
            "생리/NNG 13.849551387356703\n",
            "피임약/NNP 11.396611751920098\n",
            "일/NNB 10.957830161642615\n",
            "후/NNG 6.4447989997338775\n",
            "관계/NNG 5.6031180839354215\n",
            "되/VV 5.306145579872037\n",
            "있/VV 5.032365627962658\n",
            "복용/NNG 4.843833416219788\n",
            "==================6번째====================\n",
            "복용/NNG 11.34994717025248\n",
            "생리/NNG 9.035663499518694\n",
            "하/VV 8.972183479296778\n",
            "피임약/NNP 8.578443823620153\n",
            "후/NNG 6.587424398265254\n",
            "일/NNB 5.98236469381208\n",
            "관계/NNG 5.060264439566387\n",
            "되/VV 4.790006910065521\n",
            "먹/VV 3.8951837284302147\n",
            "임신/NNP 3.6195040339119755\n",
            "==================7번째====================\n",
            "생리/NNG 10.668757239594585\n",
            "복용/NNG 9.806062084729971\n",
            "일/NNB 8.981117715450608\n",
            "피임약/NNP 8.31668851967564\n",
            "되/VV 7.037679705962232\n",
            "먹/VV 6.613501597210918\n",
            "하/VV 6.291201802228016\n",
            "정도/NNG 3.949792049943296\n",
            "시작/NNG 3.409863218173785\n",
            "후/NNG 2.5630115846984127\n",
            "==================8번째====================\n",
            "하/VV 16.18181720818301\n",
            "복용/NNG 15.460782439750167\n",
            "피임약/NNP 9.970256942530773\n",
            "생리/NNG 9.187715874889559\n",
            "되/VV 5.582217004961955\n",
            "일/NNB 5.152882652381001\n",
            "후/NNG 4.972429616991619\n",
            "있/VV 4.1328108607360425\n",
            "먹/VV 4.073426415202891\n",
            "관계/NNG 3.1275391426876182\n",
            "==================9번째====================\n",
            "복용/NNG 10.68417404305508\n",
            "피임약/NNP 10.120634794704578\n",
            "생리/NNG 9.715198243550597\n",
            "하/VV 9.011597122151937\n",
            "일/NNB 6.777500888983371\n",
            "후/NNG 5.404210413840727\n",
            "있/VV 4.51205631053969\n",
            "먹/VV 4.305897931478895\n",
            "약/NNG 3.3895330391735015\n",
            "출혈/NNP 3.321386457357416\n",
            "==================10번째====================\n",
            "먹/VV 15.565456544799895\n",
            "일/NNB 8.42821465483716\n",
            "피임약/NNP 6.899265501099534\n",
            "생리/NNG 6.435051018915951\n",
            "있/VV 5.856464142642025\n",
            "하/VV 5.471980381535682\n",
            "되/VV 4.277096152212201\n",
            "복용/NNG 3.9951699507652254\n",
            "약/NNG 3.95005342890101\n",
            "피임/NNP 3.7159453776234885\n",
            "==================11번째====================\n",
            "생리/NNG 18.906905724373516\n",
            "일/NNB 12.483629148928474\n",
            "복용/NNG 11.382779015831108\n",
            "피임약/NNP 10.182968169636444\n",
            "시작/NNG 7.298462237014321\n",
            "먹/VV 7.024135313833702\n",
            "하/VV 6.81668946077682\n",
            "있/VV 4.993198266100831\n",
            "되/VV 4.294252020767732\n",
            "후/NNG 4.174132814822754\n",
            "==================12번째====================\n",
            "먹/VV 16.56950478517411\n",
            "피임약/NNP 12.935287076519305\n",
            "하/VV 11.090502315343244\n",
            "되/VV 8.776973595129569\n",
            "생리/NNG 7.905188748452536\n",
            "일/NNB 6.251068083143956\n",
            "관계/NNG 5.590562399557344\n",
            "후/NNG 5.112872709064086\n",
            "복용/NNG 5.084710659216795\n",
            "있/VV 4.1995776541729235\n",
            "==================13번째====================\n",
            "하/VV 6.576466087662394\n",
            "생리/NNG 5.446048516371038\n",
            "복용/NNG 4.30150302215981\n",
            "후/NNG 4.053075722990763\n",
            "번/NNB 3.154609883372798\n",
            "있/VV 1.9223493921573924\n",
            "테/NNG 1.9024850459753746\n",
            "임/NNP 1.9024850459753746\n",
            "시/NNB 1.8968917602484803\n",
            "시작/NNG 1.8942371556920667\n",
            "==================14번째====================\n",
            "복용/NNG 18.5691454763793\n",
            "일/NNB 9.624074212407672\n",
            "피임약/NNP 9.467855231296866\n",
            "하/VV 9.305315856757659\n",
            "피임/NNP 8.784179465196942\n",
            "생리/NNG 7.520279305090879\n",
            "약/NNG 7.44813022862602\n",
            "효과/NNG 6.530012916325021\n",
            "후/NNG 5.323213470893554\n",
            "먹/VV 4.9037367066044055\n",
            "==================15번째====================\n",
            "하/VV 10.61512570918264\n",
            "복용/NNG 5.920107439510177\n",
            "생리/NNG 5.006973449645452\n",
            "콘돔/NNP 4.934666274579676\n",
            "피임약/NNP 4.676615572068268\n",
            "일/NNB 4.514205394042981\n",
            "관계/NNG 3.9865884762217947\n",
            "먹/VV 3.5913347517319107\n",
            "되/VV 3.4622174560428642\n",
            "후/NNG 3.379783779178596\n",
            "==================16번째====================\n",
            "일/NNB 9.463721178022857\n",
            "하/VV 7.740745771880797\n",
            "생리/NNG 7.272197659086552\n",
            "후/NNG 5.30942142439625\n",
            "콘돔/NNP 4.570683063222031\n",
            "피임약/NNP 4.523981178860345\n",
            "받/VV 4.357251471074795\n",
            "처방/NNG 4.016862946279764\n",
            "먹/VV 3.697796993550256\n",
            "관계/NNG 3.479513334329312\n",
            "==================17번째====================\n",
            "복용/NNG 9.534104964593253\n",
            "피임약/NNP 5.327611898205846\n",
            "일/NNB 4.082206864709602\n",
            "먹/VV 4.038250193785384\n",
            "생리/NNG 3.9237268975381157\n",
            "피임/NNP 3.913203365307525\n",
            "하/VV 3.5129116164534966\n",
            "효과/NNG 3.206296253968989\n",
            "약/NNG 3.022993789983722\n",
            "피/NNG 2.413640641147184\n",
            "==================18번째====================\n",
            "하/VV 8.790182569014398\n",
            "일/NNB 6.270324344650807\n",
            "생리/NNG 4.342636857789199\n",
            "사정/NNG 4.2153527254502405\n",
            "복용/NNG 3.8559980648473053\n",
            "관계/NNG 3.8500051712593097\n",
            "후/NNG 3.826942926543516\n",
            "피임약/NNP 3.8134230859186986\n",
            "콘돔/NNP 3.342361554652381\n",
            "먹/VV 3.244082764423319\n",
            "==================19번째====================\n",
            "생리/NNG 13.61485878789264\n",
            "피임약/NNP 11.137038261141894\n",
            "하/VV 10.761957576954646\n",
            "출혈/NNP 10.220347274511772\n",
            "먹/VV 8.201118356753147\n",
            "일/NNB 7.580510605126497\n",
            "부정/NNP 7.419891967293017\n",
            "복용/NNG 7.378129508845923\n",
            "후/NNG 6.393229039179612\n",
            "되/VV 4.915680624339434\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}